#!/usr/bin/env python3
"""
TÄ±bbi Aciliyet DeÄŸerlendirme Modeli - Hugging Face Upload
Modal'da eÄŸitilmiÅŸ merge edilmiÅŸ modeli HF Hub'a yÃ¼kler
"""

import os
import json
from datetime import datetime
from huggingface_hub import HfApi, login
from transformers import AutoTokenizer, AutoModelForCausalLM

def create_medical_model_card(model_info, repo_name):
    """TÄ±bbi model iÃ§in Ã¶zel model card oluÅŸtur"""
    
    readme_content = f"""---
language:
- tr
license: apache-2.0
library_name: transformers
pipeline_tag: text-generation
tags:
- llama
- medical
- turkish
- emergency
- triage
- fine-tuned
- lora
- healthcare
base_model: unsloth/llama-3-8b-bnb-4bit
datasets:
- medical-emergency-triage
model-index:
- name: {repo_name.split('/')[-1]}
  results: []
---

# ğŸ¥ TÄ±bbi Aciliyet DeÄŸerlendirme Modeli

Bu model, **Llama-3-8B** temel modeli Ã¼zerine **LoRA (Low-Rank Adaptation)** yÃ¶ntemi ile TÃ¼rkÃ§e tÄ±bbi aciliyet verileri Ã¼zerinde fine-tune edilmiÅŸtir. Model, hasta ÅŸikayetlerini analiz ederek aciliyet seviyesi deÄŸerlendirmesi yapar.

## ğŸ¯ Model Ã–zellikleri

- **Temel Model**: `unsloth/llama-3-8b-bnb-4bit`
- **Fine-tuning YÃ¶ntemi**: LoRA (r=16, alpha=16)
- **Dil**: TÃ¼rkÃ§e ve Ä°ngilizce
- **Domain**: TÄ±bbi Aciliyet DeÄŸerlendirmesi
- **Boyut**: ~{model_info.get('total_size_gb', 15):.1f} GB
- **Maksimum Sequence Length**: 2048 tokens

## ğŸš¨ Ã–nemli UyarÄ±

âš ï¸ **Bu model sadece eÄŸitim ve araÅŸtÄ±rma amaÃ§lÄ±dÄ±r!**

- GerÃ§ek tÄ±bbi durumlar iÃ§in kullanÄ±lmamalÄ±dÄ±r
- Profesyonel tÄ±bbi tavsiye yerine geÃ§mez  
- Acil durumlarda 112'yi arayÄ±n
- Model Ã§Ä±ktÄ±larÄ± her zaman doÄŸrulanmalÄ±dÄ±r

## ğŸ“‹ KullanÄ±m AlanlarÄ±

âœ… **Uygun KullanÄ±m:**
- TÄ±bbi eÄŸitim simÃ¼lasyonlarÄ±
- AraÅŸtÄ±rma projeleri
- Triage algoritmalarÄ± geliÅŸtirme
- TÄ±bbi NLP araÅŸtÄ±rmalarÄ±

âŒ **Uygun Olmayan KullanÄ±m:**
- GerÃ§ek hasta deÄŸerlendirmesi
- Klinik karar verme
- TeÅŸhis koyma
- Tedavi Ã¶nerme


## ğŸ”§ Teknik Detaylar

### LoRA KonfigÃ¼rasyonu
- **Rank (r)**: 16
- **Alpha**: 16
- **Dropout**: 0.1
- **Target Modules**: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj
- **Bias**: none

### EÄŸitim Parametreleri
- **Batch Size**: 1 (gradient accumulation: 4)
- **Learning Rate**: 2e-4
- **Max Steps**: 30
- **Optimizer**: AdamW
- **Precision**: FP16/BF16
- **Max Length**: 512 tokens

### Prompt FormatÄ±

Model aÅŸaÄŸÄ±daki format ile eÄŸitilmiÅŸtir:

```
<|im_start|>system
Sen tÄ±bbi aciliyet deÄŸerlendirmesi yapan bir asistansÄ±n.
<|im_end|>
<|im_start|>user
Hasta ÅŸikayeti: [ÅÄ°KAYET]
Tespit edilen semptomlar: [SEMPTOMLAR]
<|im_end|>
<|im_start|>assistant
Aciliyet Seviyesi: [SEVÄ°YE]
Ã–neriler: [Ã–NERÄ°LER]
DeÄŸerlendirme: [AÃ‡IKLAMA]
<|im_end|>
```

## ğŸ“Š Model PerformansÄ±

### Aciliyet Seviyeleri
- **Ã‡ok acil**: Acil mÃ¼dahale gerekli
- **Acil**: HÄ±zlÄ± deÄŸerlendirme gerekli
- **Normal**: Rutin muayene yeterli

### Ã–rnek DeÄŸerlendirmeler

**GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ±:**
```
Aciliyet Seviyesi: YÃ¼ksek
Ã–neriler: Acil servise baÅŸvurun, EKG Ã§ekilmeli
DeÄŸerlendirme: Kardiyak olay riski yÃ¼ksek
```

**BaÅŸ AÄŸrÄ±sÄ±:**
```
Aciliyet Seviyesi: Orta
Ã–neriler: NÃ¶roloji konsÃ¼ltasyonu Ã¶nerilir
DeÄŸerlendirme: Åiddetli baÅŸ aÄŸrÄ±sÄ± ciddi sebepleri olabilir
```

## ğŸ›¡ï¸ GÃ¼venlik ve Sorumluluk

### SÄ±nÄ±rlamalar
- Model Ã§Ä±ktÄ±larÄ± %100 doÄŸru deÄŸildir
- Nadir hastalÄ±klarÄ± tanÄ±mada yetersiz olabilir
- KÃ¼ltÃ¼rel ve bÃ¶lgesel farklÄ±lÄ±klarÄ± tam yansÄ±tmayabilir
- SÃ¼rekli gÃ¼ncelleme ve iyileÅŸtirme gerektirir

### Etik KullanÄ±m
- Hasta mahremiyetini koruyun
- Model Ã¶nyargÄ±larÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurun
- ÅeffaflÄ±k ve aÃ§Ä±klanabilirlik saÄŸlayÄ±n
- DÃ¼zenli performans deÄŸerlendirmesi yapÄ±n

## ğŸ“š Akademik KullanÄ±m

### Citation

```bibtex
@misc{{medical_emergency_llama3,
    title={{TÄ±bbi Aciliyet DeÄŸerlendirme Modeli - Llama-3 Turkish Medical}},
    author={{[Doguser Yarar]}},
    year={{2025}},
    publisher={{Hugging Face}},
    howpublished={{\\url{{https://huggingface.co/{repo_name}}}}}
}}
```

## ğŸ”„ Model GÃ¼ncellemeleri

**v1.0** (AralÄ±k 2024)
- Ä°lk release
- Temel aciliyet deÄŸerlendirmesi
- TÃ¼rkÃ§e tÄ±bbi terminoloji desteÄŸi


## ğŸ“„ Lisans

Apache 2.0 - AÃ§Ä±k kaynak kullanÄ±m iÃ§in uygun

---

**ğŸ¥ SaÄŸlÄ±k alanÄ±nda AI kullanÄ±mÄ± hassas bir konudur. Bu modeli kullanÄ±rken sorumlu olun!**

**ğŸ“… Son GÃ¼ncelleme**: {datetime.now().strftime('%d %B %Y')}  
**ğŸ”§ Framework**: Transformers, Unsloth, LoRA  
**âš¡ Training**: Modal GPU A100
"""

    return readme_content

def upload_medical_model(model_path, username, model_name="llama3-medical-turkish-emergency"):
    """TÄ±bbi modeli HF Hub'a yÃ¼kle"""
    
    print("ğŸ¥ TÄ±bbi Aciliyet Modeli Upload SÃ¼reci")
    print("=" * 50)
    
    # Repository bilgileri
    repo_name = f"{username}/{model_name}"
    
    print(f"ğŸ“‹ Upload Bilgileri:")
    print(f"   - Model: {model_path}")
    print(f"   - Repository: {repo_name}")
    print(f"   - Visibility: Public")
    print(f"   - Domain: Medical Emergency Triage")
    
    # Model info topla
    model_info = {}
    if os.path.exists(model_path):
        total_size = sum(os.path.getsize(os.path.join(dirpath, filename)) 
                        for dirpath, dirnames, filenames in os.walk(model_path) 
                        for filename in filenames)
        model_info['total_size_gb'] = total_size / (1024**3)
    
    try:
        # HF API
        api = HfApi()
        
        # Repository oluÅŸtur (public)
        print("ğŸ“ Public repository oluÅŸturuluyor...")
        api.create_repo(
            repo_id=repo_name,
            private=False,  # Public yap
            repo_type="model"
        )
        print("âœ… Repository oluÅŸturuldu")
        
        # Model dosyalarÄ±nÄ± yÃ¼kle
        print("ğŸ“¤ Model dosyalarÄ± yÃ¼kleniyor...")
        api.upload_folder(
            folder_path=model_path,
            repo_id=repo_name,
            repo_type="model",
            commit_message="ğŸ¥ Upload Turkish Medical Emergency Triage Model"
        )
        print("âœ… Model dosyalarÄ± yÃ¼klendi")
        
        # README oluÅŸtur ve yÃ¼kle
        print("ğŸ“ DetaylÄ± model card oluÅŸturuluyor...")
        readme_content = create_medical_model_card(model_info, repo_name)
        
        with open("README.md", 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        api.upload_file(
            path_or_fileobj="README.md",
            path_in_repo="README.md",
            repo_id=repo_name,
            repo_type="model",
            commit_message="ğŸ“‹ Add comprehensive medical model documentation"
        )
        
        # GeÃ§ici dosyayÄ± sil
        os.remove("README.md")
        
        print("âœ… Model card yÃ¼klendi")
        
        # Tags ekle
        print("ğŸ·ï¸ Tags gÃ¼ncelleniyor...")
        api.update_repo_settings(
            repo_id=repo_name,
            repo_type="model",
            private=False
        )
        
        # Tags'i ayrÄ± bir commit olarak ekle
        api.upload_file(
            path_or_fileobj=json.dumps({"tags": ["medical", "turkish", "emergency", "triage", "llama", "lora", "healthcare"]}),
            path_in_repo="tags.json",
            repo_id=repo_name,
            repo_type="model",
            commit_message="ğŸ·ï¸ Add model tags"
        )
        
        print("ğŸ‰ Upload baÅŸarÄ±lÄ±!")
        print(f"ğŸ”— Model linki: https://huggingface.co/{repo_name}")
        print(f"ğŸ§ª Test iÃ§in: AutoModelForCausalLM.from_pretrained('{repo_name}')")
        
        return True
        
    except Exception as e:
        if "already exists" in str(e):
            print("âš ï¸  Repository zaten mevcut, gÃ¼ncelleniyor...")
            try:
                api.upload_folder(
                    folder_path=model_path,
                    repo_id=repo_name,
                    commit_message="ğŸ”„ Update medical model files"
                )
                print("âœ… Model gÃ¼ncellendi!")
                return True
            except Exception as update_error:
                print(f"âŒ GÃ¼ncelleme hatasÄ±: {update_error}")
                return False
        else:
            print(f"âŒ Upload hatasÄ±: {e}")
            return False

def main():
    """Ana upload sÃ¼reci"""
    
    print("ğŸ¤— Hugging Face Login")
    print("Token almak iÃ§in: https://huggingface.co/settings/tokens")
    token = input("HF Token (write yetkili): ").strip()
    
    # Login
    login(token=token)
    print("âœ… GiriÅŸ baÅŸarÄ±lÄ±!")
    
    # Model yolu
    model_path = input("\\nModel klasÃ¶rÃ¼ yolu (Ã¶rn: ./merged_model): ").strip()
    if not os.path.exists(model_path):
        print(f"âŒ Model klasÃ¶rÃ¼ bulunamadÄ±: {model_path}")
        return
    
    # KullanÄ±cÄ± bilgileri
    username = input("Hugging Face kullanÄ±cÄ± adÄ±nÄ±z: ").strip()
    
    # Ã–zel model adÄ± Ã¶ner
    default_name = "llama3-medical-turkish-emergency"
    custom_name = input(f"Model adÄ± (default: {default_name}): ").strip()
    model_name = custom_name if custom_name else default_name
    
    # Onay
    repo_name = f"{username}/{model_name}"
    confirm = input(f"\\n{repo_name} adÄ±yla PUBLIC upload yapmak istediÄŸinizi onaylÄ±yor musunuz? (y/N): ")
    
    if not confirm.lower().startswith('y'):
        print("âŒ Upload iptal edildi")
        return
    
    # Upload
    success = upload_medical_model(model_path, username, model_name)
    
    if success:
        print("\\nğŸŠ TÄ±bbi modeliniz baÅŸarÄ±yla yÃ¼klendi!")
        print(f"ğŸŒ Public eriÅŸim: https://huggingface.co/{repo_name}")

if __name__ == "__main__":
    main()