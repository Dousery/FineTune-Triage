# ğŸ¥ Turkish Medical Emergency Triage Model

[![Hugging Face Model](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Model-yellow)](https://huggingface.co/dousery/turkish-medical-triage-llama3-gguf)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Turkish](https://img.shields.io/badge/Language-Turkish-red)](https://github.com/topics/turkish)
[![Medical AI](https://img.shields.io/badge/Domain-Medical%20AI-green)](https://github.com/topics/medical-ai)

> **Llama-3 8B** tabanlÄ± TÃ¼rkÃ§e tÄ±bbi aciliyet deÄŸerlendirme modeli. LoRA fine-tuning ile hasta ÅŸikayetlerini analiz eder ve aciliyet seviyesi belirler.

## ğŸš€ KullanÄ±m

```python
import os
from llama_cpp import Llama

def load_model(path):
    try:
        print(f"ğŸ”„ Model yÃ¼kleniyor: {os.path.basename(path)}")
        model = Llama(model_path=path, n_ctx=4096, n_threads=8, verbose=False, n_gpu_layers=0)
        print("âœ… Model yÃ¼klendi")
        return model
    except Exception as e:
        print(f"âŒ YÃ¼kleme hatasÄ±: {e}")
        return None

def run_inference(model, prompt):
    try:
        result = model(prompt=prompt, max_tokens=300, temperature=0.5, stop=["<|im_end|>"], echo=False)
        return result['choices'][0]['text'].strip()
    except Exception as e:
        print(f"âŒ Inference hatasÄ±: {e}")
        return None

def main():
    print("ğŸš€ GGUF Model Chat - Ã‡Ä±kmak iÃ§in 'q' yaz")
    path = input("Model dosya yolu (varsayÄ±lan: model.gguf): ").strip() or "model.gguf"

    if not os.path.exists(path):
        print(f"âŒ Dosya bulunamadÄ±: {path}")
        return

    model = load_model(path)
    if not model:
        return

    while True:
        user_input = input("\nğŸ‘¤ Siz: ").strip()
        if user_input.lower() in ['q', 'quit', 'Ã§Ä±k', 'exit']:
            break
        if not user_input:
            continue

        prompt = f"""<|im_start|>system
Sen tÄ±bbi aciliyet deÄŸerlendirmesi yapan bir asistansÄ±n.
<|im_end|>
<|im_start|>user
{user_input}
<|im_end|>
<|im_start|>assistant
"""

        print("ğŸ”„ DÃ¼ÅŸÃ¼nÃ¼yor...")
        response = run_inference(model, prompt)
        print(f"ğŸ¤– Asistan: {response}" if response else "âŒ YanÄ±t alÄ±namadÄ±")

if __name__ == "__main__":
    try:
        main()
    except ImportError:
        print("âŒ llama-cpp-python eksik! YÃ¼klemek iÃ§in:\n")
        print("pip install llama-cpp-python")

```

## âš¡ Ã–zellikler

- ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e Optimize**: Native TÃ¼rkÃ§e tÄ±bbi terminoloji
- ğŸ¯ **Aciliyet SÄ±nÄ±flandÄ±rmasÄ±**: Ã‡ok Acil - Acil - Normal arasÄ± deÄŸerlendirme
- ğŸ§  **LoRA Fine-tuned**: Efficient training ile optimize edildi
- ğŸ“‹ **Triage Sistemi**: Hasta Ã¶nceliklendirmesi iÃ§in tasarlandÄ±
- âš¡ **HÄ±zlÄ± Ä°nference**: 8B parametreli efficient model

## ğŸ—ï¸ Model DetaylarÄ±

| Ã–zellik | DeÄŸer |
|---------|-------|
| **Base Model** | `unsloth/llama-3-8b-bnb-4bit` |
| **Fine-tuning** | LoRA (r=16, Î±=16) |
| **Dil** | TÃ¼rkÃ§e |
| **Max Length** | 2048 tokens |
| **Boyut** | ~15GB |

## ğŸ­ Ã–rnek Ã‡Ä±ktÄ±lar

**Input**: "BaÅŸÄ±m Ã§ok aÄŸrÄ±yor, kusma var, Ä±ÅŸÄ±k gÃ¶zÃ¼mÃ¼ yakÄ±yor"

**Output**:
```
Aciliyet Seviyesi: YÃ¼ksek
Ã–neriler: Acil servise baÅŸvurun, nÃ¶rolojik muayene gerekli
DeÄŸerlendirme: Migren veya intrakranial basÄ±nÃ§ artÄ±ÅŸÄ± olasÄ±lÄ±ÄŸÄ±
```

## âš ï¸ Ã–nemli UyarÄ±lar

> **ğŸš¨ SADECE EÄÄ°TÄ°M VE ARAÅTIRMA AMAÃ‡LIDIR**
> 
> - GerÃ§ek tÄ±bbi durumlar iÃ§in kullanmayÄ±n
> - Profesyonel tÄ±bbi tavsiye yerine geÃ§mez
> - Acil durumlarda **112**'yi arayÄ±n

## ğŸ“Š KullanÄ±m AlanlarÄ±

âœ… **Uygun**: TÄ±bbi eÄŸitim, araÅŸtÄ±rma, simÃ¼lasyon  
âŒ **Uygun DeÄŸil**: GerÃ§ek hasta deÄŸerlendirmesi, teÅŸhis

## ğŸ“„ Lisans

Apache 2.0 License - Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ”— BaÄŸlantÄ±lar

- ğŸ¤— [Hugging Face Model](https://huggingface.co/dousery/llama3-turkish-medical-triage)
- ğŸ“§ Ä°letiÅŸim: [GitHub Issues](https://github.com/dousery/FineTune-Triage/issues)

---

<div align="center">

**â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!**

*TÃ¼rkiye'de tÄ±bbi AI araÅŸtÄ±rmalara katkÄ±da bulunmasÄ± iÃ§in oluÅŸturulmuÅŸtur.*

</div>
